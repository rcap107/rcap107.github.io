{
  "hash": "3f41724d4a961866b7efc17ead79ccc3",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"TIL: Categorical, String, and Object in Pandas\"\ndate: 2025-10-25\ncategories: [Python, Pandas]\nimage: \"/images/posts/pandas-string-object-categorical.png\"\nformat:\n    html:\n        toc: true\n        code-fold: false\n        code-tools: true\n---\n\n\n\n\nIn the process of adding support for Pandas 3.0 (specifically, the object-to-str\nmigration) to skrub, I have been exposed to \nmore *fun and quirky* â„¢ features of Pandas than I'd like. One in particular,\nhowever, _really threw me for a loop_. \n\n> You can read more about the migration in the official post \n> [here](https://pandas.pydata.org/docs/user_guide/migration-3-strings.html). \n\nIn Pandas, \"object\" columns are columns that can contain pretty much anything: \nstrings, lists, or whatever else. Still, very often these columns\nare used for simple strings. Additionally,\nPandas includes String and Categorical dtypes, each with its own uses. \n\nUntil I learned what I'll explain in this post, my superficial understanding\nof these dtypes was that Categorical was a special case of String, and String\nwas a special case of Object.\n\n![](/images/posts/pandas-what-i-thought.png)\n\nAs it turns out, that isn't how things actually work under the hood.  \n\n## How did I get here?\nIn skrub, we need to support both Pandas and Polars, and so we have \na full set of private functions that implement the same functionality \nusing methods from each respective library. \n\nWhat matters for this post is the function `is_string` in  \n`skrub/_dataframe/_common.py`. The function should tell me whether a column is a\nstring column (it contains only strings), but does not have a categorical dtype,\nas those dtypes are more informative and should be treated differently from strings. \n\nThis is what the Polars function looks like:\n```python\n@is_string.specialize(\"polars\", argument_type=\"Column\")\ndef _is_string_polars(col):\n    return col.dtype == pl.String\n```\n\nWhile this is the Pandas variant:\n```python\n@is_string.specialize(\"pandas\", argument_type=\"Column\")\ndef _is_string_pandas(col):\n    if col.dtype == pd.StringDtype():\n        return True\n    if not pd.api.types.is_object_dtype(col):\n        return False\n    if parse_version(pd.__version__) < parse_version(\"2.0.0\"):\n        # on old pandas versions\n        # `pd.api.types.is_string_dtype(pd.Series([1, \"\"]))` is True\n        return col.convert_dtypes().dtype == pd.StringDtype()\n    return pandas.api.types.is_string_dtype(col[~col.isna()])\n```\n\nWhy the huge difference in complexity? To say nothing of the Pandas \n3.0-compatible version, which is about 50% longer. Well, Pandas has to deal with \na few more cases due to the fact that \"Object\" columns can be pretty much anything. \n\n## A practical example\nWhat does this mean in practice, when we want to check for a datatype? Well, \nlet's try out a few combinations and see what comes out. \n\n::: {#07f733b6 .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\n\ndf = pd.DataFrame(\n    {\n        \"cat-str\":pd.Series([\"a\", \"b\"], dtype=\"category\"),\n        \"cat-obj\": pd.Series([\"a\", 1], dtype=\"category\"),\n        \"obj-obj\": pd.Series([\"a\", 1]),\n        \"str-obj\": pd.Series([\"a\", \"b\"]),\n        \"str\": pd.Series([\"a\", \"b\"], dtype=\"string\"),\n    }\n)\nprint(df.dtypes)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ncat-str          category\ncat-obj          category\nobj-obj            object\nstr-obj            object\nstr        string[python]\ndtype: object\n```\n:::\n:::\n\n\nSo, on the surface, categorical columns are categorical, object columns are objects,\nand the column defined as a string is a string. This does make sense. \n\nHowever, relying exclusively on the string representation can encounder all sorts\nof shenanigans, so a more reliable way of checking types is by using functions\nin `pd.api.types`. \n\nSpecifically, in the function above we want to make sure that the return value is\n`True` only when all the values in the series are strings, but still return \n`False` if the string is categorical. The problem is that a series can have \nmultiple types at the same time. \n\nWe can check this with the following function, which tells us whether a column \nis considered object, categorical, or string based on `pd.api.types`: \n\n::: {#3e9d5c1d .cell execution_count=2}\n``` {.python .cell-code}\ndef print_types(df, col_name):\n    col = df[col_name]\n    print(f\"Column {col_name} has dtype StringDtype: \", col.dtype == pd.StringDtype())\n    print(f\"Column {col_name} is string dtype: \", pd.api.types.is_string_dtype(col))\n    print(f\"Column {col_name} is object dtype:\", pd.api.types.is_object_dtype(col))\n    print(f\"Column {col_name} is categorical dtype:\", pd.api.types.is_categorical_dtype(col))\n\nfor col in df:\n    print_types(df, col)\n    print(\"####\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nColumn cat-str has dtype StringDtype:  False\nColumn cat-str is string dtype:  True\nColumn cat-str is object dtype: False\nColumn cat-str is categorical dtype: True\n####\nColumn cat-obj has dtype StringDtype:  False\nColumn cat-obj is string dtype:  False\nColumn cat-obj is object dtype: False\nColumn cat-obj is categorical dtype: True\n####\nColumn obj-obj has dtype StringDtype:  False\nColumn obj-obj is string dtype:  False\nColumn obj-obj is object dtype: True\nColumn obj-obj is categorical dtype: False\n####\nColumn str-obj has dtype StringDtype:  False\nColumn str-obj is string dtype:  True\nColumn str-obj is object dtype: True\nColumn str-obj is categorical dtype: False\n####\nColumn str has dtype StringDtype:  True\nColumn str is string dtype:  True\nColumn str is object dtype: False\nColumn str is categorical dtype: False\n####\n```\n:::\n:::\n\n\nAs it turns out, each column is different! I made this neat Venn diagram to summarize\nall the combinations:\n\n![](/images/posts/pandas-string-object-categorical.png)\n\nIn short: \n\n- A categorical column is never an object, but it may also be string if it contains \nonly strings.\n- A string column may be categorical, or object, or just string. \n- An object column can also be string, if it is initialized without the `string`\ndtype. \n\nSo, what happens in the `is_string` function is:\n\n1. String-typed columns are considered as strings (function returns `True`)\n2. Categorical columns _are not objects_ so the function returns `False`\n3. If the column is `Object`, then check that it only contains strings with \n`pd.api.types.is_string_dtype()`.\n\nIf the check for `pd.api.types.is_string_dtype()` had been placed at the start of\nthe function, then *categorical columns with only strings would be considered\nas string columns*. \n\nI won't be going into the details of why this is the case (also because I did not \nlook into it), but the gist of it is that Pandas relies on Numpy for the \nunderlying data representation of dataframes, and this leads to various \ncomplications, of which this particular datatype weirdness is only one example. \nIncidentally, this is why the migration to the string datatype is being done. \n\nSo this is something I learned recently and that confused me enough to write a \npost about it. At least, now I have a better understanding of what's going on \nunder the hood. \n\n",
    "supporting": [
      "pandas-categorical-object_files"
    ],
    "filters": [],
    "includes": {}
  }
}